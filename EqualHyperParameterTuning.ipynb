{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPT4P+mMyRmhThJS02DWt2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajeswariKumaran/SSLMethodsAnalysis/blob/main/EqualHyperParameterTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmwjz5pc5ACC",
        "outputId": "ad71313a-d789-43fa-8f53-16899311a462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.5 colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# starting here"
      ],
      "metadata": {
        "id": "FbcsgfImvLEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn.functional as F\n",
        "import optuna"
      ],
      "metadata": {
        "id": "I54nIUDCvjH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the datasets and get labeled subset for fully supervised model\n",
        "# Dataset loading (CIFAR-10)\n",
        "# Dataset loading (CIFAR-10)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split into labeled and unlabeled sets\n",
        "labeled_data_size = 6000  # Assume we have 4000 labeled samples\n",
        "indices = torch.randperm(len(trainset)).tolist()\n",
        "labeled_indices = indices[:labeled_data_size]\n",
        "unlabeled_indices = indices[labeled_data_size:]\n",
        "\n",
        "labeled_trainset = Subset(trainset, labeled_indices)\n",
        "unlabeled_trainset = Subset(trainset, unlabeled_indices)\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 64\n",
        "labeled_trainloader = DataLoader(labeled_trainset, batch_size=batch_size, shuffle=True)\n",
        "unlabeled_trainloader = DataLoader(unlabeled_trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Set the proportion of validation data (e.g., 20%)\n",
        "val_split_ratio = 0.2\n",
        "\n",
        "# Compute lengths for training and validation sets\n",
        "total_size = len(labeled_trainset)\n",
        "val_size = int(total_size * val_split_ratio)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "# Perform the split\n",
        "labeled_trainset, validset = random_split(labeled_trainset, [train_size, val_size])\n",
        "\n",
        "# Now you can create DataLoaders\n",
        "labeled_trainloader = DataLoader(labeled_trainset, batch_size=64, shuffle=True)\n",
        "labeled_validloader = DataLoader(validset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "pZmsOAWevQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize hyper parameters for supervised training with only labeled data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import optuna  # Hyperparameter optimization library\n",
        "\n",
        "# Define the same model as used for SSL (for a fair comparison)\n",
        "class SupervisedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SupervisedModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Define the objective function for Optuna optimization\n",
        "def objective_supervised(trial):\n",
        "    # Hyperparameter search space\n",
        "    learning_rate = trial.suggest_loguniform('lr', 1e-5, 1e-2)  # Log scale for learning rate\n",
        "    momentum = trial.suggest_uniform('momentum', 0.5, 0.9)  # Momentum for SGD\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])  # Different batch sizes\n",
        "\n",
        "    # Create the DataLoader for labeled data\n",
        "    labeled_trainloader = DataLoader(labeled_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize the supervised model, optimizer, and loss criterion\n",
        "    model = SupervisedModel()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train the model with the current hyperparameters\n",
        "    model.train()\n",
        "    for epoch in range(10):  # Training for 10 epochs\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in labeled_trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            print(f\"Epoch {epoch+1}, Loss: {running_loss/len(labeled_trainloader)}\")\n",
        "\n",
        "    # Evaluate the model on the validation set after training\n",
        "    accuracy = evaluate_supervised_model(model, validloader)  # Assuming validloader is predefined\n",
        "    return accuracy  # Minimize the negative accuracy (maximize accuracy)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_supervised_model(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Create validation set (same as test set or separate split from training data)\n",
        "validloader = DataLoader(validset, batch_size=64, shuffle=False)  # Assuming validset is predefined\n",
        "\n",
        "# Set up Optuna study to find the best hyperparameters\n",
        "study = optuna.create_study(direction='maximize')  # We want to maximize accuracy\n",
        "study.optimize(objective_supervised, n_trials=20)  # Search for 20 trials\n",
        "\n",
        "# Print best hyperparameters and accuracy\n",
        "print(f\"Best trial: {study.best_trial.params}\")\n",
        "print(f\"Best validation accuracy: {study.best_trial.value}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U737xt-wU0G",
        "outputId": "d8aa1539-1552-47d7-a997-16e4422131ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 06:38:17,877] A new study created in memory with name: no-name-da8cf57e-c808-40d0-8344-bea00303c0c5\n",
            "/tmp/ipython-input-940294220.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lr', 1e-5, 1e-2)  # Log scale for learning rate\n",
            "/tmp/ipython-input-940294220.py:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  momentum = trial.suggest_uniform('momentum', 0.5, 0.9)  # Momentum for SGD\n",
            "[I 2025-08-31 06:38:46,982] Trial 0 finished with value: 29.75 and parameters: {'lr': 5.9321778995265514e-05, 'momentum': 0.6861471040931886, 'batch_size': 32}. Best is trial 0 with value: 29.75.\n",
            "[I 2025-08-31 06:39:16,324] Trial 1 finished with value: 40.916666666666664 and parameters: {'lr': 0.0036918306459303722, 'momentum': 0.6125154194375058, 'batch_size': 128}. Best is trial 1 with value: 40.916666666666664.\n",
            "[I 2025-08-31 06:39:46,510] Trial 2 finished with value: 31.583333333333332 and parameters: {'lr': 3.6584529346780894e-05, 'momentum': 0.8682900784531764, 'batch_size': 32}. Best is trial 1 with value: 40.916666666666664.\n",
            "[I 2025-08-31 06:40:15,112] Trial 3 finished with value: 35.166666666666664 and parameters: {'lr': 0.00037567676135449353, 'momentum': 0.7208735003982771, 'batch_size': 64}. Best is trial 1 with value: 40.916666666666664.\n",
            "[I 2025-08-31 06:40:44,786] Trial 4 finished with value: 43.75 and parameters: {'lr': 0.0007538946881591191, 'momentum': 0.858493521354901, 'batch_size': 32}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:41:13,024] Trial 5 finished with value: 30.666666666666668 and parameters: {'lr': 0.00011217708602324507, 'momentum': 0.750923795612217, 'batch_size': 64}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:41:41,478] Trial 6 finished with value: 21.0 and parameters: {'lr': 2.755115404083366e-05, 'momentum': 0.7838840610328939, 'batch_size': 64}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:42:09,804] Trial 7 finished with value: 25.416666666666668 and parameters: {'lr': 0.00011677990993087495, 'momentum': 0.5048380546784397, 'batch_size': 64}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:42:38,723] Trial 8 finished with value: 30.0 and parameters: {'lr': 9.120762909407751e-05, 'momentum': 0.7958578888929664, 'batch_size': 32}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:43:07,601] Trial 9 finished with value: 28.666666666666668 and parameters: {'lr': 0.00021950638548125348, 'momentum': 0.660372166511927, 'batch_size': 128}. Best is trial 4 with value: 43.75.\n",
            "[I 2025-08-31 06:43:36,427] Trial 10 finished with value: 47.5 and parameters: {'lr': 0.0010796558159678984, 'momentum': 0.8633451441239283, 'batch_size': 32}. Best is trial 10 with value: 47.5.\n",
            "[I 2025-08-31 06:44:05,155] Trial 11 finished with value: 49.0 and parameters: {'lr': 0.0013688737861386247, 'momentum': 0.8943309800710152, 'batch_size': 32}. Best is trial 11 with value: 49.0.\n",
            "[I 2025-08-31 06:44:34,345] Trial 12 finished with value: 50.416666666666664 and parameters: {'lr': 0.002036290891978945, 'momentum': 0.886621950599082, 'batch_size': 32}. Best is trial 12 with value: 50.416666666666664.\n",
            "[I 2025-08-31 06:45:03,180] Trial 13 finished with value: 51.083333333333336 and parameters: {'lr': 0.009309358946282688, 'momentum': 0.8910026282612258, 'batch_size': 32}. Best is trial 13 with value: 51.083333333333336.\n",
            "[I 2025-08-31 06:45:34,284] Trial 14 finished with value: 49.916666666666664 and parameters: {'lr': 0.009237466255345127, 'momentum': 0.8217751569978551, 'batch_size': 32}. Best is trial 13 with value: 51.083333333333336.\n",
            "[I 2025-08-31 06:46:02,609] Trial 15 finished with value: 51.333333333333336 and parameters: {'lr': 0.007368715747923294, 'momentum': 0.8974213852548178, 'batch_size': 32}. Best is trial 15 with value: 51.333333333333336.\n",
            "[I 2025-08-31 06:46:31,743] Trial 16 finished with value: 41.416666666666664 and parameters: {'lr': 0.006517472647736435, 'momentum': 0.5776152001943577, 'batch_size': 128}. Best is trial 15 with value: 51.333333333333336.\n",
            "[I 2025-08-31 06:46:59,915] Trial 17 finished with value: 19.583333333333332 and parameters: {'lr': 1.0097203076733225e-05, 'momentum': 0.8303189929616293, 'batch_size': 32}. Best is trial 15 with value: 51.333333333333336.\n",
            "[I 2025-08-31 06:47:29,409] Trial 18 finished with value: 50.083333333333336 and parameters: {'lr': 0.003562931381148331, 'momentum': 0.7673990372430336, 'batch_size': 32}. Best is trial 15 with value: 51.333333333333336.\n",
            "[I 2025-08-31 06:47:58,508] Trial 19 finished with value: 45.416666666666664 and parameters: {'lr': 0.004308814000048836, 'momentum': 0.8241508808559952, 'batch_size': 128}. Best is trial 15 with value: 51.333333333333336.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'lr': 0.007368715747923294, 'momentum': 0.8974213852548178, 'batch_size': 32}\n",
            "Best validation accuracy: 51.333333333333336%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supervised_best_params = study.best_trial.params"
      ],
      "metadata": {
        "id": "sJzwB6sq4w8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get best parameters for semi supervised learning using VAT\n",
        "import optuna\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define your VAT model (as in your original code)\n",
        "class VATModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VATModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Define VAT loss function\n",
        "def virtual_adversarial_loss(model, x, epsilon=1e-6):\n",
        "    x.requires_grad_()\n",
        "    logits = model(x)\n",
        "\n",
        "    # Virtual adversarial perturbation\n",
        "    loss = F.cross_entropy(logits, torch.max(logits, 1)[1])\n",
        "    loss.backward()\n",
        "    grad = x.grad\n",
        "\n",
        "    # Perturbation\n",
        "    perturbation = epsilon * torch.sign(grad)\n",
        "\n",
        "    # Perturbed data\n",
        "    x_perturbed = x + perturbation\n",
        "    logits_perturbed = model(x_perturbed)\n",
        "    loss_perturbed = F.cross_entropy(logits_perturbed, torch.max(logits, 1)[1])\n",
        "\n",
        "    return loss_perturbed\n",
        "\n",
        "# Combined loss for VAT model\n",
        "def vat_loss(model, x, labels, criterion, epsilon=1e-6, alpha=1.0):\n",
        "    # Cross-entropy loss for labeled data\n",
        "    ce_loss = criterion(model(x), labels)\n",
        "\n",
        "    # Virtual adversarial loss (VAT)\n",
        "    va_loss = virtual_adversarial_loss(model, x, epsilon)\n",
        "\n",
        "    return ce_loss + alpha * va_loss\n",
        "\n",
        "# Training function for VAT model\n",
        "def train_vat_model(model, labeled_trainloader, unlabeled_trainloader, criterion, optimizer, num_epochs=10, epsilon=1e-6, alpha=1.0):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for (inputs, labels), (inputs_unlabeled, _) in zip(labeled_trainloader, unlabeled_trainloader):\n",
        "            optimizer.zero_grad()\n",
        "            # Train on labeled data with VAT applied to unlabeled data\n",
        "            loss = vat_loss(model, inputs, labels, criterion, epsilon, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(labeled_trainloader)}\")\n",
        "\n",
        "# Optuna objective function for hyperparameter search\n",
        "def optimize_vat_hyperparameters(labeled_trainloader, unlabeled_trainloader, testloader):\n",
        "    def objective(trial):\n",
        "        # Suggest hyperparameters\n",
        "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "        momentum = trial.suggest_uniform('momentum', 0.8, 0.95)\n",
        "        epsilon = trial.suggest_loguniform('epsilon', 1e-6, 1e-1)\n",
        "        alpha = trial.suggest_uniform('alpha', 0.5, 2.0)\n",
        "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "        # Create model, optimizer, and criterion\n",
        "        model = VATModel()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # DataLoader for current batch size\n",
        "        labeled_trainloader = DataLoader(labeled_trainset, batch_size=batch_size, shuffle=True)\n",
        "        unlabeled_trainloader = DataLoader(unlabeled_trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Train the VAT model\n",
        "        train_vat_model(model, labeled_trainloader, unlabeled_trainloader, criterion, optimizer, num_epochs=10, epsilon=epsilon, alpha=alpha)\n",
        "\n",
        "        # Evaluate the model after training\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in validloader:\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        return accuracy  # Maximize accuracy\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=20)\n",
        "\n",
        "    print(f\"Best trial: {study.best_trial.value}\")\n",
        "    print(f\"Best hyperparameters: {study.best_trial.params}\")\n",
        "    return study.best_trial.params\n",
        "\n",
        "# Run hyperparameter optimization\n",
        "vat_best_params = optimize_vat_hyperparameters(labeled_trainloader, unlabeled_trainloader, testloader)\n",
        "\n",
        "# Now you can use `vat_best_params` to train the VAT model with optimal hyperparameters."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmTeLAN3zwg1",
        "outputId": "b2c133b8-1e80-4f59-cc99-f8529ce6eb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:41:36,044] A new study created in memory with name: no-name-e9ff834d-e65e-4743-a307-4802fc04eff0\n",
            "/tmp/ipython-input-772745886.py:71: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
            "/tmp/ipython-input-772745886.py:72: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  momentum = trial.suggest_uniform('momentum', 0.8, 0.95)\n",
            "/tmp/ipython-input-772745886.py:73: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  epsilon = trial.suggest_loguniform('epsilon', 1e-6, 1e-1)\n",
            "/tmp/ipython-input-772745886.py:74: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  alpha = trial.suggest_uniform('alpha', 0.5, 2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.503390174163015\n",
            "Epoch 2, Loss: 3.182346594961066\n",
            "Epoch 3, Loss: 3.1231669187545776\n",
            "Epoch 4, Loss: 3.065893813183433\n",
            "Epoch 5, Loss: 3.0262865392785323\n",
            "Epoch 6, Loss: 2.9909278781790483\n",
            "Epoch 7, Loss: 2.964064880421287\n",
            "Epoch 8, Loss: 2.940559048401682\n",
            "Epoch 9, Loss: 2.916605886660124\n",
            "Epoch 10, Loss: 2.903702735900879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:43:07,514] Trial 0 finished with value: 11.833333333333334 and parameters: {'lr': 0.0002933545621957897, 'momentum': 0.8726100152878178, 'epsilon': 2.2241271650750257e-06, 'alpha': 0.6242247997400614, 'batch_size': 128}. Best is trial 0 with value: 11.833333333333334.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.9939275328318278\n",
            "Epoch 2, Loss: 3.320546964009603\n",
            "Epoch 3, Loss: 3.1655237038930255\n",
            "Epoch 4, Loss: 3.0780448627471926\n",
            "Epoch 5, Loss: 2.9674384212493896\n",
            "Epoch 6, Loss: 2.819689718882243\n",
            "Epoch 7, Loss: 2.3940446472167967\n",
            "Epoch 8, Loss: 2.1679722690582275\n",
            "Epoch 9, Loss: 2.064407498041789\n",
            "Epoch 10, Loss: 1.9316555070877075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:44:38,457] Trial 1 finished with value: 48.75 and parameters: {'lr': 0.0055408037667521, 'momentum': 0.9106519230578937, 'epsilon': 0.0002303768254359234, 'alpha': 1.8719397650367253, 'batch_size': 64}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.2542110430566886\n",
            "Epoch 2, Loss: 3.237873522858871\n",
            "Epoch 3, Loss: 3.1323172418694747\n",
            "Epoch 4, Loss: 3.0956427674544487\n",
            "Epoch 5, Loss: 3.073359169458088\n",
            "Epoch 6, Loss: 3.0486476986031783\n",
            "Epoch 7, Loss: 3.021965353112472\n",
            "Epoch 8, Loss: 3.009729780648884\n",
            "Epoch 9, Loss: 2.993721183977629\n",
            "Epoch 10, Loss: 2.9797720156217875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:46:11,849] Trial 2 finished with value: 9.916666666666666 and parameters: {'lr': 9.43220258284373e-05, 'momentum': 0.8659118689218435, 'epsilon': 1.746439925258192e-06, 'alpha': 0.5400523056802289, 'batch_size': 128}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.1680461883544924\n",
            "Epoch 2, Loss: 2.9140812428792318\n",
            "Epoch 3, Loss: 2.831033765474955\n",
            "Epoch 4, Loss: 2.76817040125529\n",
            "Epoch 5, Loss: 2.7190186484654744\n",
            "Epoch 6, Loss: 2.677310883204142\n",
            "Epoch 7, Loss: 2.641738576889038\n",
            "Epoch 8, Loss: 2.6025713284810386\n",
            "Epoch 9, Loss: 2.5645540793736776\n",
            "Epoch 10, Loss: 2.5073161856333415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:47:45,769] Trial 3 finished with value: 16.75 and parameters: {'lr': 0.0003354520278501304, 'momentum': 0.924309375146222, 'epsilon': 6.503816544194226e-06, 'alpha': 0.6659601437557676, 'batch_size': 32}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.7331960805257163\n",
            "Epoch 2, Loss: 3.4729818312327065\n",
            "Epoch 3, Loss: 3.3995107714335124\n",
            "Epoch 4, Loss: 3.3461879444122316\n",
            "Epoch 5, Loss: 3.3080249627431235\n",
            "Epoch 6, Loss: 3.27389222462972\n",
            "Epoch 7, Loss: 3.2491898345947265\n",
            "Epoch 8, Loss: 3.2243780453999835\n",
            "Epoch 9, Loss: 3.205532162984212\n",
            "Epoch 10, Loss: 3.1858344173431394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:49:20,346] Trial 4 finished with value: 11.25 and parameters: {'lr': 0.00030723953083488316, 'momentum': 0.8540882294190101, 'epsilon': 0.0004216536471012794, 'alpha': 1.3314548775094712, 'batch_size': 64}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.609454374564321\n",
            "Epoch 2, Loss: 3.7104692710073373\n",
            "Epoch 3, Loss: 3.554553690709566\n",
            "Epoch 4, Loss: 3.450389084063078\n",
            "Epoch 5, Loss: 3.364758560532018\n",
            "Epoch 6, Loss: 3.2872485173375985\n",
            "Epoch 7, Loss: 3.205483122875816\n",
            "Epoch 8, Loss: 3.116397782375938\n",
            "Epoch 9, Loss: 3.023719906806946\n",
            "Epoch 10, Loss: 2.940094508622822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:50:52,481] Trial 5 finished with value: 8.666666666666666 and parameters: {'lr': 0.0005889932913617048, 'momentum': 0.9021824322033115, 'epsilon': 0.07601371843631557, 'alpha': 1.6809140950568353, 'batch_size': 128}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.921592469215393\n",
            "Epoch 2, Loss: 3.693658216794332\n",
            "Epoch 3, Loss: 3.657158850034078\n",
            "Epoch 4, Loss: 3.6280328305562337\n",
            "Epoch 5, Loss: 3.6024501498540245\n",
            "Epoch 6, Loss: 3.579818008740743\n",
            "Epoch 7, Loss: 3.5594992955525715\n",
            "Epoch 8, Loss: 3.543055313428243\n",
            "Epoch 9, Loss: 3.525134859085083\n",
            "Epoch 10, Loss: 3.5104642216364543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:52:28,310] Trial 6 finished with value: 11.833333333333334 and parameters: {'lr': 2.362737749699348e-05, 'momentum': 0.83130733258469, 'epsilon': 0.004017988604013305, 'alpha': 1.4112009962459717, 'batch_size': 32}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.9748768186569214\n",
            "Epoch 2, Loss: 3.4743271112442016\n",
            "Epoch 3, Loss: 3.364459335009257\n",
            "Epoch 4, Loss: 3.28841548760732\n",
            "Epoch 5, Loss: 3.227428631782532\n",
            "Epoch 6, Loss: 3.1700661977132163\n",
            "Epoch 7, Loss: 3.1228035847345987\n",
            "Epoch 8, Loss: 3.079485586484273\n",
            "Epoch 9, Loss: 3.03784996509552\n",
            "Epoch 10, Loss: 2.9975254662831623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:54:05,025] Trial 7 finished with value: 12.333333333333334 and parameters: {'lr': 0.0004992026563587909, 'momentum': 0.9323393471471606, 'epsilon': 0.00043438340462051054, 'alpha': 1.8851383509439765, 'batch_size': 32}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.5712318054835\n",
            "Epoch 2, Loss: 3.3763566970825196\n",
            "Epoch 3, Loss: 3.3091321245829266\n",
            "Epoch 4, Loss: 3.2612923431396483\n",
            "Epoch 5, Loss: 3.2254502693812053\n",
            "Epoch 6, Loss: 3.1953337399164834\n",
            "Epoch 7, Loss: 3.1671636708577475\n",
            "Epoch 8, Loss: 3.1479291613896687\n",
            "Epoch 9, Loss: 3.126456408500671\n",
            "Epoch 10, Loss: 3.108420893351237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:55:40,674] Trial 8 finished with value: 9.416666666666666 and parameters: {'lr': 0.0002579358176957561, 'momentum': 0.8141048194135886, 'epsilon': 1.2736444707960457e-05, 'alpha': 1.2271725036673269, 'batch_size': 32}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.363462282816569\n",
            "Epoch 2, Loss: 3.0513845984141033\n",
            "Epoch 3, Loss: 2.918692766825358\n",
            "Epoch 4, Loss: 2.785106976826986\n",
            "Epoch 5, Loss: 2.677261637846629\n",
            "Epoch 6, Loss: 2.7888553206125897\n",
            "Epoch 7, Loss: 2.8338710792859394\n",
            "Epoch 8, Loss: 2.6334113478660583\n",
            "Epoch 9, Loss: 2.713365747133891\n",
            "Epoch 10, Loss: 2.5568069624900818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:57:07,499] Trial 9 finished with value: 18.583333333333332 and parameters: {'lr': 0.026096991764774945, 'momentum': 0.9394170424257748, 'epsilon': 1.121213674983256e-05, 'alpha': 0.6935880215844469, 'batch_size': 32}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.222530946731568\n",
            "Epoch 2, Loss: 3.2792523161570233\n",
            "Epoch 3, Loss: 3.0922235584259035\n",
            "Epoch 4, Loss: 2.8033577537536623\n",
            "Epoch 5, Loss: 2.5493736362457273\n",
            "Epoch 6, Loss: 2.447369016011556\n",
            "Epoch 7, Loss: 2.204736895561218\n",
            "Epoch 8, Loss: 2.191259420712789\n",
            "Epoch 9, Loss: 2.044482192993164\n",
            "Epoch 10, Loss: 1.825566504796346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 07:58:36,337] Trial 10 finished with value: 45.75 and parameters: {'lr': 0.012535001592627755, 'momentum': 0.906860967250878, 'epsilon': 7.458241898462628e-05, 'alpha': 1.9645990885495477, 'batch_size': 64}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.968388833999634\n",
            "Epoch 2, Loss: 3.300257008870443\n",
            "Epoch 3, Loss: 3.0173553244272866\n",
            "Epoch 4, Loss: 2.6825317351023354\n",
            "Epoch 5, Loss: 2.4764795446395875\n",
            "Epoch 6, Loss: 2.3096696106592813\n",
            "Epoch 7, Loss: 2.1818543418248493\n",
            "Epoch 8, Loss: 2.037479732831319\n",
            "Epoch 9, Loss: 1.9471484772364298\n",
            "Epoch 10, Loss: 1.7742943207422892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:00:04,494] Trial 11 finished with value: 47.0 and parameters: {'lr': 0.010845855109372325, 'momentum': 0.9016137211898128, 'epsilon': 7.359596355837667e-05, 'alpha': 1.9784424339354418, 'batch_size': 64}. Best is trial 1 with value: 48.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.782855895360311\n",
            "Epoch 2, Loss: 3.268344472249349\n",
            "Epoch 3, Loss: 3.1434936714172363\n",
            "Epoch 4, Loss: 3.0304377110799154\n",
            "Epoch 5, Loss: 2.964245500564575\n",
            "Epoch 6, Loss: 2.8584439309438068\n",
            "Epoch 7, Loss: 2.6124488353729247\n",
            "Epoch 8, Loss: 2.4158937803904217\n",
            "Epoch 9, Loss: 2.176226708094279\n",
            "Epoch 10, Loss: 2.076652863820394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:01:37,910] Trial 12 finished with value: 49.75 and parameters: {'lr': 0.004683444236568706, 'momentum': 0.8915845187796497, 'epsilon': 7.633183703505233e-05, 'alpha': 1.6675574886555689, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.808923956553141\n",
            "Epoch 2, Loss: 3.365183130900065\n",
            "Epoch 3, Loss: 3.2429240385691327\n",
            "Epoch 4, Loss: 3.167512413660685\n",
            "Epoch 5, Loss: 3.1065325133005777\n",
            "Epoch 6, Loss: 3.0493707847595215\n",
            "Epoch 7, Loss: 2.9952682081858315\n",
            "Epoch 8, Loss: 2.9475677490234373\n",
            "Epoch 9, Loss: 2.9077593580881755\n",
            "Epoch 10, Loss: 2.861718772252401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:03:10,575] Trial 13 finished with value: 17.333333333333332 and parameters: {'lr': 0.0034804064404314644, 'momentum': 0.8897746638506009, 'epsilon': 0.002046914060295387, 'alpha': 1.6824098444121782, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.8537770398457845\n",
            "Epoch 2, Loss: 3.2900181516011555\n",
            "Epoch 3, Loss: 3.174587526321411\n",
            "Epoch 4, Loss: 3.0904971917470294\n",
            "Epoch 5, Loss: 3.0026851431528727\n",
            "Epoch 6, Loss: 2.9335293134053546\n",
            "Epoch 7, Loss: 2.8631920210520425\n",
            "Epoch 8, Loss: 2.715961227416992\n",
            "Epoch 9, Loss: 2.5019987042744956\n",
            "Epoch 10, Loss: 2.370544106165568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:04:44,021] Trial 14 finished with value: 30.833333333333332 and parameters: {'lr': 0.002584554397761117, 'momentum': 0.9152923827083421, 'epsilon': 9.322360920772776e-05, 'alpha': 1.607861335162541, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 5.506511516571045\n",
            "Epoch 2, Loss: 3.4921219730377198\n",
            "Epoch 3, Loss: 3.4540666929880777\n",
            "Epoch 4, Loss: 3.408139279683431\n",
            "Epoch 5, Loss: 3.36717635790507\n",
            "Epoch 6, Loss: 3.325817330678304\n",
            "Epoch 7, Loss: 3.28755446434021\n",
            "Epoch 8, Loss: 3.243302904764811\n",
            "Epoch 9, Loss: 3.1727186012268067\n",
            "Epoch 10, Loss: 3.180309368769328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:06:04,460] Trial 15 finished with value: 14.25 and parameters: {'lr': 0.09962500191148407, 'momentum': 0.9490698900898161, 'epsilon': 0.002075467998735307, 'alpha': 1.0711633244063599, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.7548627185821535\n",
            "Epoch 2, Loss: 3.317526038487752\n",
            "Epoch 3, Loss: 3.207225348154704\n",
            "Epoch 4, Loss: 3.1455707995096844\n",
            "Epoch 5, Loss: 3.0829796600341797\n",
            "Epoch 6, Loss: 3.0330856291453046\n",
            "Epoch 7, Loss: 2.9898232968648273\n",
            "Epoch 8, Loss: 2.94745033899943\n",
            "Epoch 9, Loss: 2.917167631785075\n",
            "Epoch 10, Loss: 2.8884943548838296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:07:37,662] Trial 16 finished with value: 13.083333333333334 and parameters: {'lr': 0.002565513331896745, 'momentum': 0.8804068921404457, 'epsilon': 0.013141111271268434, 'alpha': 1.5140783821577934, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.9703250058492023\n",
            "Epoch 2, Loss: 3.216384932200114\n",
            "Epoch 3, Loss: 3.030789581934611\n",
            "Epoch 4, Loss: 2.7381956990559897\n",
            "Epoch 5, Loss: 2.6109069045384725\n",
            "Epoch 6, Loss: 2.4731252066294354\n",
            "Epoch 7, Loss: 2.252580580711365\n",
            "Epoch 8, Loss: 2.18709902604421\n",
            "Epoch 9, Loss: 2.0614030996958417\n",
            "Epoch 10, Loss: 1.989538623491923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:09:02,858] Trial 17 finished with value: 39.916666666666664 and parameters: {'lr': 0.04392108587174598, 'momentum': 0.8446960130935948, 'epsilon': 0.00020802899322891046, 'alpha': 1.7955947870691342, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.4485055764516193\n",
            "Epoch 2, Loss: 2.984088484446208\n",
            "Epoch 3, Loss: 2.8282949924468994\n",
            "Epoch 4, Loss: 2.4647935485839843\n",
            "Epoch 5, Loss: 2.180817084312439\n",
            "Epoch 6, Loss: 2.03221075852712\n",
            "Epoch 7, Loss: 1.8462496916453044\n",
            "Epoch 8, Loss: 1.778871579170227\n",
            "Epoch 9, Loss: 1.6450654109319052\n",
            "Epoch 10, Loss: 1.5741627661387125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:10:32,782] Trial 18 finished with value: 48.0 and parameters: {'lr': 0.006093240840507661, 'momentum': 0.8888334970311471, 'epsilon': 2.396935059500899e-05, 'alpha': 1.077791455233288, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.949950205485026\n",
            "Epoch 2, Loss: 3.4121944363911947\n",
            "Epoch 3, Loss: 3.3067706489562987\n",
            "Epoch 4, Loss: 3.2310439205169676\n",
            "Epoch 5, Loss: 3.176257158915202\n",
            "Epoch 6, Loss: 3.1254377714792887\n",
            "Epoch 7, Loss: 3.0729797649383546\n",
            "Epoch 8, Loss: 3.034290132522583\n",
            "Epoch 9, Loss: 2.9915740426381427\n",
            "Epoch 10, Loss: 2.9537227598826092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 08:12:03,079] Trial 19 finished with value: 10.666666666666666 and parameters: {'lr': 0.0013267130301124423, 'momentum': 0.9189905399254423, 'epsilon': 0.0006977728075051315, 'alpha': 1.799684167772557, 'batch_size': 64}. Best is trial 12 with value: 49.75.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 49.75\n",
            "Best hyperparameters: {'lr': 0.004683444236568706, 'momentum': 0.8915845187796497, 'epsilon': 7.633183703505233e-05, 'alpha': 1.6675574886555689, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now compare the performance of VAT and fully supervised using respective best parameters\n",
        "\n",
        "# Initialize and train the fully-supervised model using best parameters\n",
        "# Define Fully-Supervised Model (Simple CNN)\n",
        "class FullySupervisedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FullySupervisedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = FullySupervisedCNN()\n",
        "optimizer = optim.SGD(model.parameters(), lr=supervised_best_params['lr'], momentum=supervised_best_params['momentum'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function for models\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
        "\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9u7GwaH0CSy",
        "outputId": "2641e8ba-97c4-40d4-a75d-3830debe8287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4652755618705164\n",
            "Epoch 2, Loss: 1.1664301307152605\n",
            "Epoch 3, Loss: 1.047432781332899\n",
            "Epoch 4, Loss: 0.9822487318912125\n",
            "Epoch 5, Loss: 0.9283737188105083\n",
            "Epoch 6, Loss: 0.8880558254392555\n",
            "Epoch 7, Loss: 0.8585296645951088\n",
            "Epoch 8, Loss: 0.827574706710208\n",
            "Epoch 9, Loss: 0.806894422301551\n",
            "Epoch 10, Loss: 0.7838642739731333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ssl_model = VATModel()\n",
        "optimizer_ssl = optim.SGD(ssl_model.parameters(), lr=vat_best_params['lr'], momentum=vat_best_params['momentum'])\n",
        "\n",
        "# Define criterion for VAT model\n",
        "criterion_ssl = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function for VAT model\n",
        "def train_vat_model(model, labeled_trainloader, unlabeled_trainloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for (inputs, labels), (inputs_unlabeled, _) in zip(labeled_trainloader, unlabeled_trainloader):\n",
        "            optimizer.zero_grad()\n",
        "            # Train on labeled data with VAT applied to unlabeled data\n",
        "            loss = vat_loss(model, inputs, labels, criterion, alpha=1.0, epsilon=1e-6)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(labeled_trainloader)}\")\n",
        "\n",
        "# Train SSL (VAT) model\n",
        "\n",
        "train_vat_model(ssl_model, labeled_trainloader, unlabeled_trainloader, criterion_ssl, optimizer_ssl, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FLUWQLt5QFL",
        "outputId": "717bb101-1b64-4319-b620-5c7a14b6016d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.3468048350016275\n",
            "Epoch 2, Loss: 2.9587280813852948\n",
            "Epoch 3, Loss: 2.8115629291534425\n",
            "Epoch 4, Loss: 2.688424596786499\n",
            "Epoch 5, Loss: 2.3976821835835773\n",
            "Epoch 6, Loss: 2.1479301420847574\n",
            "Epoch 7, Loss: 1.9474782896041871\n",
            "Epoch 8, Loss: 1.797435245513916\n",
            "Epoch 9, Loss: 1.7121193997065227\n",
            "Epoch 10, Loss: 1.6093256950378418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate function\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# ssl_model_accuracy = evaluate(ssl_model)\n",
        "# print(f\"SSL (VAT) model accuracy: {ssl_model_accuracy}%\")"
      ],
      "metadata": {
        "id": "v-IxjHCr7TYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare performance of SSL (VAT) vs Fully-supervised\n",
        "fully_supervised_accuracy = evaluate(model)\n",
        "ssl_model_accuracy = evaluate(ssl_model)\n",
        "\n",
        "print(f\"Fully-supervised model accuracy: {fully_supervised_accuracy}%\")\n",
        "print(f\"SSL (VAT) model accuracy: {ssl_model_accuracy}%\")\n",
        "\n",
        "# Justifying the claim: Narrow performance gap under equal hyperparameter tuning\n",
        "if fully_supervised_accuracy >= ssl_model_accuracy:\n",
        "    print(\"The performance gap between SSL (VAT) and fully-supervised methods is narrower when hyperparameters are optimally tuned.\")\n",
        "else:\n",
        "    print(\"SSL (VAT) methods outperform fully-supervised methods, even with optimal tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5r3ECvA7x5j",
        "outputId": "c3d499d6-186b-474a-f81b-e074e7339293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fully-supervised model accuracy: 63.22%\n",
            "SSL (VAT) model accuracy: 49.46%\n",
            "The performance gap between SSL (VAT) and fully-supervised methods is narrower when hyperparameters are optimally tuned.\n"
          ]
        }
      ]
    }
  ]
}